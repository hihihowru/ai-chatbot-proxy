import json
import time
from typing import Dict, List, Optional
from datetime import datetime
import os

class TokenTracker:
    """
    OpenAI API Token ä½¿ç”¨é‡è¿½è¹¤å™¨
    è¨˜éŒ„æ¯æ¬¡ API èª¿ç”¨çš„ token ä½¿ç”¨æƒ…æ³å’Œæˆæœ¬
    """
    
    def __init__(self, log_file: str = "token_usage.json"):
        self.log_file = log_file
        self.usage_log = []
        self.load_existing_log()
    
    def load_existing_log(self):
        """è¼‰å…¥ç¾æœ‰çš„ä½¿ç”¨è¨˜éŒ„"""
        try:
            if os.path.exists(self.log_file):
                with open(self.log_file, 'r', encoding='utf-8') as f:
                    self.usage_log = json.load(f)
        except Exception as e:
            print(f"è¼‰å…¥ token è¨˜éŒ„å¤±æ•—: {e}")
            self.usage_log = []
    
    def record_api_call(self, 
                       node_name: str,
                       model: str,
                       prompt_tokens: int,
                       completion_tokens: int,
                       total_tokens: int,
                       cost: float,
                       user_input: str = "",
                       stock_id: str = "",
                       success: bool = True,
                       error_message: str = ""):
        """
        è¨˜éŒ„ä¸€æ¬¡ API èª¿ç”¨
        
        Args:
            node_name: ç¯€é»åç¨± (å¦‚ classify_and_extract)
            model: ä½¿ç”¨çš„æ¨¡å‹ (å¦‚ gpt-3.5-turbo)
            prompt_tokens: è¼¸å…¥ token æ•¸é‡
            completion_tokens: è¼¸å‡º token æ•¸é‡
            total_tokens: ç¸½ token æ•¸é‡
            cost: æˆæœ¬ (ç¾å…ƒ)
            user_input: ç”¨æˆ¶è¼¸å…¥
            stock_id: è‚¡ç¥¨ä»£è™Ÿ
            success: æ˜¯å¦æˆåŠŸ
            error_message: éŒ¯èª¤è¨Šæ¯
        """
        record = {
            "timestamp": datetime.now().isoformat(),
            "node_name": node_name,
            "model": model,
            "prompt_tokens": prompt_tokens,
            "completion_tokens": completion_tokens,
            "total_tokens": total_tokens,
            "cost_usd": cost,
            "user_input": user_input[:200],  # é™åˆ¶é•·åº¦
            "stock_id": stock_id,
            "success": success,
            "error_message": error_message
        }
        
        self.usage_log.append(record)
        self.save_log()
        
        # å³æ™‚è¼¸å‡º
        print(f"ğŸ”¢ Token ä½¿ç”¨è¨˜éŒ„: {node_name} | è¼¸å…¥: {prompt_tokens} | è¼¸å‡º: {completion_tokens} | ç¸½è¨ˆ: {total_tokens} | æˆæœ¬: ${cost:.4f}")
    
    def save_log(self):
        """å„²å­˜ä½¿ç”¨è¨˜éŒ„åˆ°æª”æ¡ˆ"""
        try:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                json.dump(self.usage_log, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"å„²å­˜ token è¨˜éŒ„å¤±æ•—: {e}")
    
    def get_usage_summary(self, 
                         start_date: Optional[str] = None,
                         end_date: Optional[str] = None,
                         node_name: Optional[str] = None) -> Dict:
        """
        å–å¾—ä½¿ç”¨é‡æ‘˜è¦
        
        Args:
            start_date: é–‹å§‹æ—¥æœŸ (ISO æ ¼å¼)
            end_date: çµæŸæ—¥æœŸ (ISO æ ¼å¼)
            node_name: ç‰¹å®šç¯€é»åç¨±
        
        Returns:
            ä½¿ç”¨é‡æ‘˜è¦å­—å…¸
        """
        filtered_log = self.usage_log.copy()
        
        # æ—¥æœŸç¯©é¸
        if start_date:
            filtered_log = [r for r in filtered_log if r["timestamp"] >= start_date]
        if end_date:
            filtered_log = [r for r in filtered_log if r["timestamp"] <= end_date]
        
        # ç¯€é»ç¯©é¸
        if node_name:
            filtered_log = [r for r in filtered_log if r["node_name"] == node_name]
        
        if not filtered_log:
            return {
                "total_calls": 0,
                "total_prompt_tokens": 0,
                "total_completion_tokens": 0,
                "total_tokens": 0,
                "total_cost": 0.0,
                "success_rate": 0.0,
                "node_breakdown": {}
            }
        
        # è¨ˆç®—çµ±è¨ˆ
        total_calls = len(filtered_log)
        total_prompt_tokens = sum(r["prompt_tokens"] for r in filtered_log)
        total_completion_tokens = sum(r["completion_tokens"] for r in filtered_log)
        total_tokens = sum(r["total_tokens"] for r in filtered_log)
        total_cost = sum(r["cost_usd"] for r in filtered_log)
        success_calls = sum(1 for r in filtered_log if r["success"])
        success_rate = success_calls / total_calls if total_calls > 0 else 0
        
        # ç¯€é»ç´°åˆ†
        node_breakdown = {}
        for record in filtered_log:
            node = record["node_name"]
            if node not in node_breakdown:
                node_breakdown[node] = {
                    "calls": 0,
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0,
                    "cost": 0.0
                }
            
            node_breakdown[node]["calls"] += 1
            node_breakdown[node]["prompt_tokens"] += record["prompt_tokens"]
            node_breakdown[node]["completion_tokens"] += record["completion_tokens"]
            node_breakdown[node]["total_tokens"] += record["total_tokens"]
            node_breakdown[node]["cost"] += record["cost_usd"]
        
        return {
            "total_calls": total_calls,
            "total_prompt_tokens": total_prompt_tokens,
            "total_completion_tokens": total_completion_tokens,
            "total_tokens": total_tokens,
            "total_cost": total_cost,
            "success_rate": success_rate,
            "node_breakdown": node_breakdown
        }
    
    def calculate_cost(self, model: str, prompt_tokens: int, completion_tokens: int) -> float:
        """
        è¨ˆç®— API èª¿ç”¨æˆæœ¬
        
        Args:
            model: æ¨¡å‹åç¨±
            prompt_tokens: è¼¸å…¥ token æ•¸é‡
            completion_tokens: è¼¸å‡º token æ•¸é‡
        
        Returns:
            æˆæœ¬ (ç¾å…ƒ)
        """
        # OpenAI å®šåƒ¹ (2024å¹´)
        pricing = {
            "gpt-3.5-turbo": {
                "input": 0.0015,   # $0.0015 per 1K tokens
                "output": 0.002    # $0.002 per 1K tokens
            },
            "gpt-4": {
                "input": 0.03,     # $0.03 per 1K tokens
                "output": 0.06     # $0.06 per 1K tokens
            },
            "gpt-4-turbo": {
                "input": 0.01,     # $0.01 per 1K tokens
                "output": 0.03     # $0.03 per 1K tokens
            }
        }
        
        if model not in pricing:
            # é è¨­ä½¿ç”¨ gpt-3.5-turbo å®šåƒ¹
            model = "gpt-3.5-turbo"
        
        input_cost = (prompt_tokens / 1000) * pricing[model]["input"]
        output_cost = (completion_tokens / 1000) * pricing[model]["output"]
        
        return input_cost + output_cost
    
    def get_daily_usage(self, date: str) -> Dict:
        """å–å¾—ç‰¹å®šæ—¥æœŸçš„ä½¿ç”¨é‡"""
        start_date = f"{date}T00:00:00"
        end_date = f"{date}T23:59:59"
        return self.get_usage_summary(start_date, end_date)
    
    def get_monthly_usage(self, year: int, month: int) -> Dict:
        """å–å¾—ç‰¹å®šæœˆä»½çš„ä½¿ç”¨é‡"""
        start_date = f"{year:04d}-{month:02d}-01T00:00:00"
        if month == 12:
            end_date = f"{year+1:04d}-01-01T00:00:00"
        else:
            end_date = f"{year:04d}-{month+1:02d}-01T00:00:00"
        return self.get_usage_summary(start_date, end_date)
    
    def export_report(self, filename: str = None) -> str:
        """åŒ¯å‡ºä½¿ç”¨å ±å‘Š"""
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"token_usage_report_{timestamp}.json"
        
        summary = self.get_usage_summary()
        report = {
            "generated_at": datetime.now().isoformat(),
            "summary": summary,
            "detailed_log": self.usage_log
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        return filename

# å…¨åŸŸå¯¦ä¾‹
token_tracker = TokenTracker()

def track_openai_call(node_name: str, 
                     response, 
                     user_input: str = "",
                     stock_id: str = "",
                     success: bool = True,
                     error_message: str = ""):
    """
    è¿½è¹¤ OpenAI API èª¿ç”¨çš„ä¾¿æ·å‡½æ•¸
    
    Args:
        node_name: ç¯€é»åç¨±
        response: OpenAI API å›æ‡‰ç‰©ä»¶
        user_input: ç”¨æˆ¶è¼¸å…¥
        stock_id: è‚¡ç¥¨ä»£è™Ÿ
        success: æ˜¯å¦æˆåŠŸ
        error_message: éŒ¯èª¤è¨Šæ¯
    """
    try:
        if hasattr(response, 'usage'):
            usage = response.usage
            model = response.model if hasattr(response, 'model') else "gpt-3.5-turbo"
            
            cost = token_tracker.calculate_cost(
                model,
                usage.prompt_tokens,
                usage.completion_tokens
            )
            
            token_tracker.record_api_call(
                node_name=node_name,
                model=model,
                prompt_tokens=usage.prompt_tokens,
                completion_tokens=usage.completion_tokens,
                total_tokens=usage.total_tokens,
                cost=cost,
                user_input=user_input,
                stock_id=stock_id,
                success=success,
                error_message=error_message
            )
        else:
            print(f"âš ï¸ ç„¡æ³•è¿½è¹¤ token ä½¿ç”¨é‡: {node_name} - å›æ‡‰ç‰©ä»¶ç¼ºå°‘ usage å±¬æ€§")
            
    except Exception as e:
        print(f"âŒ Token è¿½è¹¤å¤±æ•—: {e}")

# æ¸¬è©¦ç”¨
if __name__ == "__main__":
    # æ¨¡æ“¬æ¸¬è©¦
    tracker = TokenTracker("test_token_usage.json")
    
    # æ¨¡æ“¬è¨˜éŒ„
    tracker.record_api_call(
        node_name="classify_and_extract",
        model="gpt-3.5-turbo",
        prompt_tokens=150,
        completion_tokens=50,
        total_tokens=200,
        cost=0.0004,
        user_input="å°ç©é›»æ€éº¼æ¨£ï¼Ÿ",
        stock_id="2330"
    )
    
    # é¡¯ç¤ºæ‘˜è¦
    summary = tracker.get_usage_summary()
    print("Token ä½¿ç”¨æ‘˜è¦:")
    print(json.dumps(summary, ensure_ascii=False, indent=2)) 