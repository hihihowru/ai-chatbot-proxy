import requests
import json
import re
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import os
from bs4 import BeautifulSoup
import openai
import time

def crawl_cmoney_forum(stock_id: str) -> Dict:
    """
    çˆ¬å– CMoney åŒå­¸æœƒè¨è«–å€çš„è²¼æ–‡
    
    Args:
        stock_id: è‚¡ç¥¨ä»£è™Ÿ
    
    Returns:
        åŒ…å«è²¼æ–‡åˆ—è¡¨çš„å­—å…¸
    """
    try:
        print(f"[DEBUG] ğŸ” é–‹å§‹çˆ¬å–åŒå­¸æœƒè¨è«–å€ï¼Œè‚¡ç¥¨ä»£è™Ÿ: {stock_id}")
        
        # æ§‹å»º URL
        url = f"https://www.cmoney.tw/forum/stock/{stock_id}"
        
        # è¨­ç½® headers æ¨¡æ“¬ç€è¦½å™¨
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        
        print(f"[DEBUG] ğŸ“¡ ç™¼é€è«‹æ±‚åˆ°: {url}")
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            print(f"[DEBUG] âŒ è«‹æ±‚å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return {
                "success": False,
                "error": f"HTTP {response.status_code}",
                "posts": []
            }
        
        print(f"[DEBUG] âœ… è«‹æ±‚æˆåŠŸï¼Œé–‹å§‹è§£æé é¢")
        
        # è§£æ HTML
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # å°‹æ‰¾è¨è«–è²¼æ–‡
        posts = []
        
        # å˜—è©¦å¤šç¨®å¯èƒ½çš„é¸æ“‡å™¨ä¾†æ‰¾åˆ°è²¼æ–‡
        selectors = [
            '.article-item',  # å¯èƒ½çš„æ–‡ç« é …ç›®é¸æ“‡å™¨
            '.post-item',     # å¯èƒ½çš„è²¼æ–‡é …ç›®é¸æ“‡å™¨
            '.discussion-item', # å¯èƒ½çš„è¨è«–é …ç›®é¸æ“‡å™¨
            'article',        # æ–‡ç« æ¨™ç±¤
            '.content-item',  # å…§å®¹é …ç›®
        ]
        
        found_posts = False
        for selector in selectors:
            post_elements = soup.select(selector)
            if post_elements:
                print(f"[DEBUG] ğŸ” ä½¿ç”¨é¸æ“‡å™¨ '{selector}' æ‰¾åˆ° {len(post_elements)} å€‹å…ƒç´ ")
                found_posts = True
                
                for i, element in enumerate(post_elements[:20]):  # é™åˆ¶å‰20å€‹
                    try:
                        # æå–æ¨™é¡Œ
                        title_element = element.select_one('h1, h2, h3, .title, .post-title')
                        title = title_element.get_text(strip=True) if title_element else f"è²¼æ–‡ {i+1}"
                        
                        # æå–å…§å®¹æ‘˜è¦
                        content_element = element.select_one('.content, .post-content, .summary, p')
                        content = content_element.get_text(strip=True) if content_element else ""
                        
                        # æå–æ™‚é–“
                        time_element = element.select_one('.time, .date, .post-time, time')
                        post_time = time_element.get_text(strip=True) if time_element else "æœªçŸ¥æ™‚é–“"
                        
                        # æå–ç•™è¨€æ•¸
                        reply_element = element.select_one('.reply-count, .comment-count, .count')
                        reply_count = reply_element.get_text(strip=True) if reply_element else "0"
                        
                        # æ¸…ç†ç•™è¨€æ•¸
                        reply_count = re.sub(r'[^\d]', '', reply_count)
                        reply_count = int(reply_count) if reply_count.isdigit() else 0
                        
                        post = {
                            "title": title,
                            "content": content,
                            "time": post_time,
                            "reply_count": reply_count,
                            "sentiment": "neutral"  # é è¨­ç‚ºä¸­ç«‹
                        }
                        
                        posts.append(post)
                        print(f"[DEBUG] ğŸ“ æå–è²¼æ–‡ {i+1}: {title[:50]}... (ç•™è¨€æ•¸: {reply_count})")
                        
                    except Exception as e:
                        print(f"[DEBUG] âš ï¸ æå–è²¼æ–‡ {i+1} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        continue
                
                break
        
        if not found_posts:
            print(f"[DEBUG] âš ï¸ æœªæ‰¾åˆ°è²¼æ–‡ï¼Œå˜—è©¦æå–é é¢æ–‡å­—å…§å®¹")
            # å¦‚æœæ‰¾ä¸åˆ°ç‰¹å®šçµæ§‹ï¼Œå˜—è©¦æå–é é¢ä¸­çš„æ–‡å­—å…§å®¹
            text_content = soup.get_text()
            
            # å°‹æ‰¾å¯èƒ½çš„è¨è«–å…§å®¹
            lines = text_content.split('\n')
            for line in lines:
                line = line.strip()
                if len(line) > 20 and any(keyword in line for keyword in ['è¨è«–', 'åˆ†äº«', 'åˆ†æ', 'çœ‹æ³•', 'å»ºè­°']):
                    posts.append({
                        "title": "è¨è«–å…§å®¹",
                        "content": line[:200] + "..." if len(line) > 200 else line,
                        "time": "æœªçŸ¥æ™‚é–“",
                        "reply_count": 0,
                        "sentiment": "neutral"
                    })
        
        print(f"[DEBUG] ğŸ“Š ç¸½å…±æå–åˆ° {len(posts)} å€‹è²¼æ–‡")
        
        return {
            "success": True,
            "posts": posts,
            "total_count": len(posts)
        }
        
    except Exception as e:
        print(f"[DEBUG] âŒ çˆ¬å–åŒå­¸æœƒè¨è«–å€å¤±æ•—: {e}")
        return {
            "success": False,
            "error": str(e),
            "posts": []
        }

def analyze_sentiment(text: str) -> str:
    """
    åˆ†ææ–‡æœ¬æƒ…ç·’
    
    Args:
        text: è¦åˆ†æçš„æ–‡æœ¬
    
    Returns:
        æƒ…ç·’æ¨™ç±¤: positive, negative, neutral
    """
    try:
        # æ­£å‘é—œéµè©
        positive_keywords = [
            'çœ‹æ¼²', 'åˆ©å¤š', 'åŠ ç¢¼', 'AI', 'ç‡Ÿæ”¶å‰µé«˜', 'æˆé•·', 'çœ‹å¥½', 'å¼·å‹¢', 'çªç ´',
            'è²·é€²', 'æ¨è–¦', 'æ©Ÿæœƒ', 'æ¨‚è§€', 'ä¸Šæ¼²', 'æ¼²åœ', 'å¥½', 'æ£’', 'è®š', 'å²å®³',
            'è³ºéŒ¢', 'ç²åˆ©', 'è±æ”¶', 'æˆåŠŸ', 'å„ªç§€', 'å‚‘å‡º', 'äº®çœ¼', 'é©šè‰·'
        ]
        
        # è² å‘é—œéµè©
        negative_keywords = [
            'çœ‹ç©º', 'è·Œ', 'çˆ†é‡å€’è²¨', 'çˆ›', 'è½‰å¼±', 'è³£å‡º', 'é¿é–‹', 'é¢¨éšª', 'ä¸‹è·Œ',
            'è·Œåœ', 'å£', 'ç³Ÿ', 'å·®', 'è™§æ', 'è³ éŒ¢', 'å¤±æ•—', 'ç³Ÿç³•', 'å¤±æœ›', 'æ“”æ†‚',
            'ææ…Œ', 'ææ‡¼', 'æ‚²è§€', 'çœ‹è¡°', 'ä¸çœ‹å¥½', 'å•é¡Œ', 'å›°é›£', 'æŒ‘æˆ°'
        ]
        
        text_lower = text.lower()
        
        # è¨ˆç®—æ­£å‘å’Œè² å‘é—œéµè©å‡ºç¾æ¬¡æ•¸
        positive_count = sum(1 for keyword in positive_keywords if keyword in text_lower)
        negative_count = sum(1 for keyword in negative_keywords if keyword in text_lower)
        
        # åˆ¤æ–·æƒ…ç·’
        if positive_count > negative_count:
            return "positive"
        elif negative_count > positive_count:
            return "negative"
        else:
            return "neutral"
            
    except Exception as e:
        print(f"[DEBUG] âš ï¸ æƒ…ç·’åˆ†æå¤±æ•—: {e}")
        return "neutral"

def generate_social_sentiment_section(company_name: str, stock_id: str) -> Dict:
    """
    ç”¢ç”ŸåŒå­¸æœƒè¼¿æƒ…åˆ†æ section
    
    Args:
        company_name: å…¬å¸åç¨±
        stock_id: è‚¡ç¥¨ä»£è™Ÿ
    
    Returns:
        è¼¿æƒ…åˆ†æ section çš„ JSON æ ¼å¼
    """
    try:
        print(f"[DEBUG] ğŸ¯ é–‹å§‹ç”¢ç”ŸåŒå­¸æœƒè¼¿æƒ…åˆ†æ section")
        print(f"[DEBUG] å…¬å¸åç¨±: {company_name}")
        print(f"[DEBUG] è‚¡ç¥¨ä»£è™Ÿ: {stock_id}")
        
        # 1. çˆ¬å–åŒå­¸æœƒè¨è«–å€
        crawl_result = crawl_cmoney_forum(stock_id)
        
        if not crawl_result.get("success"):
            print(f"[DEBUG] âŒ çˆ¬å–å¤±æ•—ï¼Œä½¿ç”¨é è¨­å…§å®¹")
            return {
                "success": False,
                "section": {
                    "section": "ç¤¾ç¾¤è¼¿æƒ…è§€å¯Ÿ",
                    "cards": [
                        {
                            "title": "ç¤¾ç¾¤è¨è«–ç†±åº¦",
                            "content": [
                                {
                                    "text": f"ç›®å‰ {company_name}({stock_id}) åœ¨è‚¡å¸‚çˆ†æ–™åŒå­¸æœƒçš„è¨è«–ç†±åº¦ä¸é«˜ï¼Œæš«ç„¡æ˜ç¢ºçš„ç¤¾ç¾¤è¼¿æƒ…è§€å¯Ÿã€‚"
                                }
                            ]
                        }
                    ]
                },
                "error": crawl_result.get("error", "çˆ¬å–å¤±æ•—")
            }
        
        posts = crawl_result.get("posts", [])
        print(f"[DEBUG] ğŸ“Š æˆåŠŸçˆ¬å– {len(posts)} å€‹è²¼æ–‡")
        
        # 2. åˆ†ææƒ…ç·’
        sentiment_counts = {"positive": 0, "negative": 0, "neutral": 0}
        analyzed_posts = []
        
        for post in posts:
            # åˆ†ææ¨™é¡Œå’Œå…§å®¹çš„æƒ…ç·’
            title_sentiment = analyze_sentiment(post.get("title", ""))
            content_sentiment = analyze_sentiment(post.get("content", ""))
            
            # ç¶œåˆæƒ…ç·’åˆ¤æ–·
            if title_sentiment == content_sentiment:
                final_sentiment = title_sentiment
            elif title_sentiment != "neutral" and content_sentiment == "neutral":
                final_sentiment = title_sentiment
            elif content_sentiment != "neutral" and title_sentiment == "neutral":
                final_sentiment = content_sentiment
            else:
                final_sentiment = "neutral"
            
            post["sentiment"] = final_sentiment
            sentiment_counts[final_sentiment] += 1
            analyzed_posts.append(post)
        
        print(f"[DEBUG] ğŸ“ˆ æƒ…ç·’åˆ†æçµæœ: æ­£å‘ {sentiment_counts['positive']}, è² å‘ {sentiment_counts['negative']}, ä¸­ç«‹ {sentiment_counts['neutral']}")
        
        # 3. æ‰¾å‡ºç†±é–€è¨è«–
        sorted_posts = sorted(analyzed_posts, key=lambda x: x.get("reply_count", 0), reverse=True)
        hot_posts = sorted_posts[:3]  # å–å‰3å€‹æœ€ç†±é–€çš„
        
        # 4. è¨ˆç®—è¨è«–ç†±åº¦
        total_posts = len(posts)
        total_replies = sum(post.get("reply_count", 0) for post in posts)
        
        # 5. ç”Ÿæˆè¼¿æƒ…æ‘˜è¦
        sentiment_summary = ""
        if total_posts > 0:
            positive_ratio = sentiment_counts["positive"] / total_posts
            negative_ratio = sentiment_counts["negative"] / total_posts
            neutral_ratio = sentiment_counts["neutral"] / total_posts
            
            if positive_ratio > 0.5:
                sentiment_summary = "ç¤¾ç¾¤å°è©²è‚¡åæ¨‚è§€"
            elif negative_ratio > 0.5:
                sentiment_summary = "ç¤¾ç¾¤å°è©²è‚¡åä¿å®ˆ"
            elif positive_ratio > negative_ratio:
                sentiment_summary = "ç¤¾ç¾¤å°è©²è‚¡ç•¥åæ¨‚è§€"
            elif negative_ratio > positive_ratio:
                sentiment_summary = "ç¤¾ç¾¤å°è©²è‚¡ç•¥åä¿å®ˆ"
            else:
                sentiment_summary = "ç¤¾ç¾¤å°è©²è‚¡æ„è¦‹åˆ†æ­§"
        else:
            sentiment_summary = "ç¤¾ç¾¤è¨è«–ç†±åº¦ä¸é«˜"
        
        # 6. ä½¿ç”¨ LLM ç”Ÿæˆæœ€çµ‚å ±å‘Š
        hot_posts_text = ""
        for i, post in enumerate(hot_posts, 1):
            hot_posts_text += f"{i}. æ¨™é¡Œ: {post.get('title', 'ç„¡æ¨™é¡Œ')}\n"
            hot_posts_text += f"   å…§å®¹: {post.get('content', 'ç„¡å…§å®¹')[:100]}...\n"
            hot_posts_text += f"   æƒ…ç·’: {post.get('sentiment', 'neutral')}\n"
            hot_posts_text += f"   ç•™è¨€æ•¸: {post.get('reply_count', 0)}\n\n"
        
        prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æŠ•è³‡åˆ†æå¸«ï¼Œè«‹æ ¹æ“šä»¥ä¸‹åŒå­¸æœƒè¨è«–å€çš„è³‡æ–™ï¼Œç‚º {company_name}({stock_id}) ç”Ÿæˆç¤¾ç¾¤è¼¿æƒ…è§€å¯Ÿå ±å‘Šã€‚

è¨è«–çµ±è¨ˆï¼š
- ç¸½è²¼æ–‡æ•¸: {total_posts}
- ç¸½ç•™è¨€æ•¸: {total_replies}
- æƒ…ç·’åˆ†å¸ƒ: æ­£å‘ {sentiment_counts['positive']} ç¯‡, è² å‘ {sentiment_counts['negative']} ç¯‡, ä¸­ç«‹ {sentiment_counts['neutral']} ç¯‡

ç†±é–€è¨è«–ï¼š
{hot_posts_text}

è«‹ç”Ÿæˆå®¢è§€ã€ä¸­ç«‹çš„è¼¿æƒ…è§€å¯Ÿå ±å‘Šï¼ŒåŒ…å«ï¼š
1. è¨è«–ç†±åº¦åˆ†æ
2. æƒ…ç·’åˆ†å¸ƒåˆ†æ
3. ç†±é–€è¨è«–ä¸»é¡Œæ‘˜è¦
4. ç¤¾ç¾¤è§€å¯Ÿçµè«–

è«‹å›å‚³ JSON æ ¼å¼ï¼š
{{
  "section": "ç¤¾ç¾¤è¼¿æƒ…è§€å¯Ÿ",
  "cards": [
    {{
      "title": "è¨è«–ç†±åº¦åˆ†æ",
      "content": [
        {{
          "text": "éå»48å°æ™‚å…§ï¼Œ{company_name}({stock_id})åœ¨è‚¡å¸‚çˆ†æ–™åŒå­¸æœƒå…±æœ‰{total_posts}ç¯‡ç›¸é—œè¨è«–ï¼Œç¸½ç•™è¨€æ•¸é”{total_replies}å‰‡ã€‚"
        }},
        {{
          "text": "ç›¸æ¯”å¹³å‡è¨è«–ç†±åº¦ï¼Œç›®å‰è¨è«–ç†±åº¦{'åé«˜' if total_posts > 10 else 'åä½'}ã€‚"
        }}
      ]
    }},
    {{
      "title": "æƒ…ç·’åˆ†å¸ƒåˆ†æ",
      "content": [
        {{
          "text": "ç¤¾ç¾¤æƒ…ç·’åˆ†å¸ƒï¼šæ­£å‘ {sentiment_counts['positive']}ç¯‡({positive_ratio:.1%})ã€è² å‘ {sentiment_counts['negative']}ç¯‡({negative_ratio:.1%})ã€ä¸­ç«‹ {sentiment_counts['neutral']}ç¯‡({neutral_ratio:.1%})ã€‚"
        }},
        {{
          "text": "æ•´é«”è€Œè¨€ï¼Œ{sentiment_summary}ã€‚"
        }}
      ]
    }},
    {{
      "title": "ç†±é–€è¨è«–ä¸»é¡Œ",
      "content": [
        {{
          "text": "æœ€å—é—œæ³¨çš„è¨è«–ä¸»é¡ŒåŒ…æ‹¬ï¼š"
        }}
      ]
    }}
  ]
}}

è«‹æ ¹æ“šå¯¦éš›è³‡æ–™èª¿æ•´å…§å®¹ï¼Œä¿æŒå®¢è§€ä¸­ç«‹ã€‚
"""
        
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )
        
        raw_content = response.choices[0].message.content.strip()
        print(f"[DEBUG] ğŸ¤– LLM åŸå§‹å›å‚³å…§å®¹ï¼š\n{raw_content}")
        
        # è§£æ JSON
        try:
            result = json.loads(raw_content)
            
            # æ·»åŠ ç†±é–€è¨è«–çš„è©³ç´°å…§å®¹
            if result.get("cards") and len(result["cards"]) >= 3:
                hot_discussion_card = result["cards"][2]
                if hot_discussion_card.get("title") == "ç†±é–€è¨è«–ä¸»é¡Œ":
                    for i, post in enumerate(hot_posts, 1):
                        hot_discussion_card["content"].append({
                            "text": f"**{i}. {post.get('title', 'ç„¡æ¨™é¡Œ')}**\n{post.get('content', 'ç„¡å…§å®¹')[:150]}...\n(ç•™è¨€æ•¸: {post.get('reply_count', 0)}, æƒ…ç·’: {post.get('sentiment', 'neutral')})"
                        })
            
            print(f"[DEBUG] âœ… åŒå­¸æœƒè¼¿æƒ…åˆ†æç”¢ç”ŸæˆåŠŸ")
            return {
                "success": True,
                "section": result,
                "debug_info": {
                    "total_posts": total_posts,
                    "total_replies": total_replies,
                    "sentiment_counts": sentiment_counts,
                    "hot_posts_count": len(hot_posts)
                }
            }
            
        except json.JSONDecodeError as e:
            print(f"[DEBUG] âŒ JSON è§£æå¤±æ•—: {e}")
            # è¿”å›é è¨­å…§å®¹
            return {
                "success": False,
                "section": {
                    "section": "ç¤¾ç¾¤è¼¿æƒ…è§€å¯Ÿ",
                    "cards": [
                        {
                            "title": "è¨è«–ç†±åº¦åˆ†æ",
                            "content": [
                                {
                                    "text": f"éå»48å°æ™‚å…§ï¼Œ{company_name}({stock_id})åœ¨è‚¡å¸‚çˆ†æ–™åŒå­¸æœƒå…±æœ‰{total_posts}ç¯‡ç›¸é—œè¨è«–ã€‚"
                                }
                            ]
                        },
                        {
                            "title": "æƒ…ç·’åˆ†å¸ƒåˆ†æ",
                            "content": [
                                {
                                    "text": f"ç¤¾ç¾¤æƒ…ç·’åˆ†å¸ƒï¼šæ­£å‘ {sentiment_counts['positive']}ç¯‡ã€è² å‘ {sentiment_counts['negative']}ç¯‡ã€ä¸­ç«‹ {sentiment_counts['neutral']}ç¯‡ã€‚"
                                },
                                {
                                    "text": f"æ•´é«”è€Œè¨€ï¼Œ{sentiment_summary}ã€‚"
                                }
                            ]
                        }
                    ]
                },
                "error": f"JSON è§£æå¤±æ•—: {e}"
            }
        
    except Exception as e:
        print(f"[DEBUG] âŒ åŒå­¸æœƒè¼¿æƒ…åˆ†æå¤±æ•—: {e}")
        return {
            "success": False,
            "section": {
                "section": "ç¤¾ç¾¤è¼¿æƒ…è§€å¯Ÿ",
                "cards": [
                    {
                        "title": "ç¤¾ç¾¤è¨è«–ç†±åº¦",
                        "content": [
                            {
                                "text": f"ç›®å‰ {company_name}({stock_id}) åœ¨è‚¡å¸‚çˆ†æ–™åŒå­¸æœƒçš„è¨è«–ç†±åº¦ä¸é«˜ï¼Œæš«ç„¡æ˜ç¢ºçš„ç¤¾ç¾¤è¼¿æƒ…è§€å¯Ÿã€‚"
                            }
                        ]
                    }
                ]
            },
            "error": str(e)
        }

# æ¸¬è©¦ç”¨
if __name__ == "__main__":
    test_result = generate_social_sentiment_section("å°ç©é›»", "2330")
    print(json.dumps(test_result, ensure_ascii=False, indent=2)) 