import requests
import json
import openai
from typing import List, Dict
import re
from datetime import datetime
import os

# å®šç¾©å…è¨±çš„ä¾†æºç¶²ç«™
ALLOWED_SITES = [
    "tw.finance.yahoo.com",  # Yahooå¥‡æ‘©è‚¡å¸‚
    "cnyes.com",  # é‰…äº¨ç¶²
    "moneydj.com",  # MoneyDJ ç†è²¡ç¶²
    "cmoney.tw",  # CMoney
    "money.udn.com",  # ç¶“æ¿Ÿæ—¥å ±
    "ctee.com.tw",  # å·¥å•†æ™‚å ±
    "finance.ettoday.net",  # ETtoday è²¡ç¶“
    "goodinfo.tw",  # Goodinfo
    "macromicro.me",  # è²¡ç¶“Må¹³æ–¹
    "smart.businessweekly.com.tw",  # Smartæ™ºå¯Œ
    "technews.tw",  # ç§‘æŠ€æ–°å ±
    "nownews.com",  # Nownews
    "moneylink.com.tw",  # MoneyLink å¯Œè¯ç¶²
    "stockfeel.com.tw",  # è‚¡æ„Ÿ StockFeel
    "businessweekly.com.tw",  # å•†æ¥­å‘¨åˆŠ
    "businesstoday.com.tw",  # ä»Šå‘¨åˆŠ
    "pchome.com.tw",  # PChome è‚¡å¸‚é »é“
]

PROMPT = '''ä½ æ˜¯ä¸€å€‹å°ˆæ¥­æŠ•è³‡åˆ†æåŠ©ç†ï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…è¼¸å…¥çš„å•é¡Œï¼Œè‡ªå‹•ç”Ÿæˆä¸€çµ„ç²¾æº–çš„æœå°‹é—œéµå­—ï¼Œå¹«åŠ©æŸ¥æ‰¾æœ€æ–°ä¸”èˆ‡å°è‚¡ç›¸é—œçš„è²¡ç¶“æ–°èæˆ–æ•¸æ“šè³‡è¨Šã€‚

âš ï¸é™åˆ¶ä¾†æºï¼šè«‹åƒ…å¾ä¸‹åˆ—ç¶²ç«™ä¸­æŠ“å–å…§å®¹ï¼ˆå‡ºç¾åœ¨æ¨™é¡Œã€ç¶²å€æˆ–ä¾†æºä¸­æ‰ç´å…¥ï¼‰ï¼š
Yahooå¥‡æ‘©è‚¡å¸‚ã€é‰…äº¨ç¶² (cnyes)ã€MoneyDJ ç†è²¡ç¶²ã€CMoneyã€ç¶“æ¿Ÿæ—¥å ±ã€å·¥å•†æ™‚å ±ã€ETtoday è²¡ç¶“ã€Goodinfoã€è²¡ç¶“Må¹³æ–¹ï¼ˆMacroMicroï¼‰ã€Smartæ™ºå¯Œã€ç§‘æŠ€æ–°å ±ã€Nownewsã€MoneyLink å¯Œè¯ç¶²ã€è‚¡æ„Ÿ StockFeelã€å•†æ¥­å‘¨åˆŠã€ä»Šå‘¨åˆŠã€PChome è‚¡å¸‚é »é“ã€‚

ğŸ§ ä½¿ç”¨è€…è¼¸å…¥æœƒåŒ…å«ã€Œå…¬å¸åç¨± / è‚¡ç¥¨ä»£ç¢¼ + å•é¡Œã€ï¼Œè«‹æ ¹æ“šé€™äº›è³‡è¨Šç”Ÿæˆå…·å‚™é«˜è³‡è¨Šå¯†åº¦çš„æŸ¥è©¢çµ„åˆï¼Œä¸¦è©¦è‘—æ¶µè“‹ä»¥ä¸‹ä¸»é¡Œï¼š
- è²¡å ±æ•¸æ“šï¼ˆä¾‹ï¼šEPSã€ç‡Ÿæ”¶ã€æ¯›åˆ©ç‡ï¼‰
- è‚¡åƒ¹ç•°å‹•è§£é‡‹
- æ³•äººç±Œç¢¼æˆ–æŠ•ä¿¡ã€å¤–è³‡å‹•æ…‹
- åˆ†é»ä¸»åŠ›å‹•å‘
- æœ€æ–°æ–°èäº‹ä»¶
- ETFã€ç”¢æ¥­è¼ªå‹•ã€é¡Œæç™¼é…µ
- åˆ†æå¸«é ä¼°èˆ‡ç›®æ¨™åƒ¹

ğŸ“Œè«‹ä¸€æ¬¡å›å‚³ 8-12 çµ„å…·ä»£è¡¨æ€§çš„æœå°‹é—œéµå­—çµ„åˆï¼Œä¸¦å……åˆ†åˆ©ç”¨æ‰€æœ‰å…è¨±çš„ç¶²ç«™ã€‚æ¯å€‹ç¶²ç«™è‡³å°‘ç”Ÿæˆä¸€å€‹é—œéµå­—ã€‚

è¼¸å…¥è³‡è¨Šï¼š
- å…¬å¸åç¨±ï¼š{{ company_name }}
- è‚¡ç¥¨ä»£è™Ÿï¼š{{ stock_id }}
- å•é¡Œé¡å‹ï¼š{{ intent }}
- é—œéµå­—ï¼š{{ keywords }}
- æ™‚é–“è³‡è¨Šï¼š{{ time_info }}

è¼¸å‡ºæ ¼å¼ç‚º JSON é™£åˆ—ï¼Œè«‹åŒ…å«ä»¥ä¸‹ç¶²ç«™çš„é—œéµå­—ï¼š
[
  "{{ company_name }} {{ stock_id }} è²¡å ± site:tw.finance.yahoo.com",
  "{{ company_name }} å¤–è³‡è²·è³£ site:cnyes.com",
  "{{ stock_id }} æ³•äººå‹•å‘ site:moneydj.com",
  "{{ company_name }} EPS åˆ†æ site:cmoney.tw",
  "{{ company_name }} è²¡ç¶“æ–°è site:money.udn.com",
  "{{ stock_id }} å·¥å•†æ™‚å ± site:ctee.com.tw",
  "{{ company_name }} è²¡ç¶“å ±å° site:finance.ettoday.net",
  "{{ company_name }} åŸºæœ¬é¢ site:goodinfo.tw",
  "{{ company_name }} ç¸½é«”ç¶“æ¿Ÿ site:macromicro.me",
  "{{ company_name }} æŠ•è³‡ç†è²¡ site:smart.businessweekly.com.tw",
  "{{ company_name }} ç§‘æŠ€æ–°è site:technews.tw",
  "{{ company_name }} å³æ™‚æ–°è site:nownews.com"
]
'''

def generate_search_keywords(company_name: str, stock_id: str, intent: str, keywords: List[str], event_type: str = '', time_info: str = '') -> List[str]:
    """ç”Ÿæˆæœå°‹é—œéµè©ï¼Œç´å…¥äº‹ä»¶é¡å‹ã€æ™‚é–“ã€æ„åœ–ï¼Œå»é™¤é‡è¤‡ï¼Œè²¡å ±ç­‰è©å„ªå…ˆ"""
    try:
        # ä½¿ç”¨ OpenAI ç”Ÿæˆæ›´ç²¾æº–çš„æœå°‹é—œéµå­—
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # æº–å‚™ prompt
        prompt = PROMPT.replace("{{ company_name }}", company_name or "")
        prompt = prompt.replace("{{ stock_id }}", stock_id or "")
        prompt = prompt.replace("{{ intent }}", intent or "")
        prompt = prompt.replace("{{ keywords }}", ", ".join(keywords) if keywords else "")
        prompt = prompt.replace("{{ time_info }}", time_info or "")
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        content = response.choices[0].message.content.strip()
        
        # è§£æ JSON å›æ‡‰
        try:
            keywords_list = json.loads(content)
            if isinstance(keywords_list, list):
                return keywords_list[:12]  # å¢åŠ åˆ°æœ€å¤š12å€‹é—œéµå­—
        except json.JSONDecodeError:
            # å¦‚æœ JSON è§£æå¤±æ•—ï¼Œå˜—è©¦æå–å¼•è™Ÿå…§çš„å…§å®¹
            import re
            matches = re.findall(r'"([^"]+)"', content)
            if matches:
                return matches[:12]
        
        # å¦‚æœ AI ç”Ÿæˆå¤±æ•—ï¼Œä½¿ç”¨é è¨­é—œéµå­—
        return generate_fallback_keywords(company_name, stock_id, intent, keywords, time_info)
        
    except Exception as e:
        print(f"[generate_search_keywords ERROR] {e}")
        return generate_fallback_keywords(company_name, stock_id, intent, keywords, time_info)

def generate_fallback_keywords(company_name: str, stock_id: str, intent: str, keywords: List[str], time_info: str = '') -> List[str]:
    """ç”Ÿæˆå‚™ç”¨çš„æœå°‹é—œéµå­—ï¼Œå……åˆ†åˆ©ç”¨æ‰€æœ‰å…è¨±çš„ç¶²ç«™"""
    fallback_keywords = []
    
    # åŸºç¤çµ„åˆ - å……åˆ†åˆ©ç”¨æ‰€æœ‰ä¸»è¦ç¶²ç«™
    if company_name and stock_id:
        fallback_keywords.extend([
            f"{company_name} {stock_id} è²¡å ± site:tw.finance.yahoo.com",
            f"{company_name} å¤–è³‡è²·è³£ site:cnyes.com",
            f"{stock_id} æ³•äººå‹•å‘ site:moneydj.com",
            f"{company_name} EPS åˆ†æ site:cmoney.tw",
            f"{company_name} è²¡ç¶“æ–°è site:money.udn.com",
            f"{stock_id} å·¥å•†æ™‚å ± site:ctee.com.tw",
            f"{company_name} è²¡ç¶“å ±å° site:finance.ettoday.net",
            f"{company_name} åŸºæœ¬é¢ site:goodinfo.tw",
            f"{company_name} ç¸½é«”ç¶“æ¿Ÿ site:macromicro.me",
            f"{company_name} æŠ•è³‡ç†è²¡ site:smart.businessweekly.com.tw",
            f"{company_name} ç§‘æŠ€æ–°è site:technews.tw",
            f"{company_name} å³æ™‚æ–°è site:nownews.com"
        ])
    
    # æ ¹æ“šæ„åœ–æ·»åŠ ç‰¹å®šé—œéµå­—
    if "è²¡å ±" in intent or "åŸºæœ¬é¢" in intent:
        fallback_keywords.extend([
            f"{company_name} ç‡Ÿæ”¶ æ¯›åˆ©ç‡ site:cmoney.tw",
            f"{stock_id} æç›Šè¡¨ site:goodinfo.tw",
            f"{company_name} è²¡å‹™åˆ†æ site:tw.finance.yahoo.com"
        ])
    
    if "ç±Œç¢¼" in intent or "æ³•äºº" in intent:
        fallback_keywords.extend([
            f"{stock_id} ä¸‰å¤§æ³•äºº site:goodinfo.tw",
            f"{company_name} å¤–è³‡æŒè‚¡ site:cnyes.com",
            f"{stock_id} æŠ•ä¿¡å‹•å‘ site:moneydj.com"
        ])
    
    if "æŠ€è¡“" in intent:
        fallback_keywords.extend([
            f"{company_name} æŠ€è¡“åˆ†æ site:tw.finance.yahoo.com",
            f"{stock_id} æŠ€è¡“ç·šåœ– site:cmoney.tw",
            f"{company_name} æŠ€è¡“æŒ‡æ¨™ site:goodinfo.tw"
        ])
    
    # æ·»åŠ æ™‚é–“ç›¸é—œé—œéµå­—
    if time_info:
        fallback_keywords.extend([
            f"{company_name} {time_info} æ–°è site:cnyes.com",
            f"{stock_id} {time_info} å ±å° site:money.udn.com",
            f"{company_name} {time_info} åˆ†æ site:finance.ettoday.net"
        ])
    
    # æ·»åŠ å¹´ä»½ç›¸é—œé—œéµå­—
    current_year = "2025"
    last_year = "2024"
    if company_name:
        fallback_keywords.extend([
            f"{company_name} {current_year} è²¡å ± site:tw.finance.yahoo.com",
            f"{company_name} {last_year} æç›Šè¡¨ site:cnyes.com",
            f"{stock_id} {current_year} æ³•äººå‹•å‘ site:moneydj.com"
        ])
    
    # å»é™¤é‡è¤‡ä¸¦é™åˆ¶æ•¸é‡
    unique_keywords = list(dict.fromkeys(fallback_keywords))
    return unique_keywords[:12]  # å¢åŠ åˆ°æœ€å¤š12å€‹é—œéµå­—

def filter_results_by_site(results: List[Dict]) -> List[Dict]:
    """éæ¿¾çµæœï¼Œåªä¿ç•™å…è¨±çš„ç¶²ç«™"""
    filtered_results = []
    
    for result in results:
        link = result.get("link", "").lower()
        title = result.get("title", "").lower()
        
        # æª¢æŸ¥æ˜¯å¦ä¾†è‡ªå…è¨±çš„ç¶²ç«™
        is_allowed = False
        site_name = ""
        
        for site in ALLOWED_SITES:
            if site in link or site.replace(".", "") in link:
                is_allowed = True
                site_name = site
                break
        
        if is_allowed:
            # æ·»åŠ ç¶²ç«™è³‡è¨Šåˆ°çµæœä¸­
            result["site_name"] = site_name
            result["filtered"] = True
            filtered_results.append(result)
        else:
            # æ¨™è¨˜ç‚ºè¢«éæ¿¾çš„çµæœ
            result["filtered"] = False
    
    return filtered_results

def extract_date_from_result(result: Dict) -> str:
    """å¾æœå°‹çµæœä¸­æå–æ—¥æœŸè³‡è¨Š"""
    try:
        # å¾æ¨™é¡Œæˆ–æ‘˜è¦ä¸­å°‹æ‰¾æ—¥æœŸæ¨¡å¼
        text = f"{result.get('title', '')} {result.get('snippet', '')}"
        
        # å¸¸è¦‹çš„æ—¥æœŸæ¨¡å¼
        date_patterns = [
            r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)',  # 2024å¹´1æœˆ1æ—¥
            r'(\d{4}/\d{1,2}/\d{1,2})',      # 2024/1/1
            r'(\d{4}-\d{1,2}-\d{1,2})',      # 2024-1-1
            r'(\d{1,2}/\d{1,2})',            # 1/1
            r'(ä»Šå¤©|æ˜¨å¤©|å‰å¤©|æ˜å¤©)',         # ç›¸å°æ—¥æœŸ
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1)
        
        return "ç„¡æ—¥æœŸè³‡è¨Š"
        
    except Exception as e:
        print(f"[extract_date_from_result ERROR] {e}")
        return "ç„¡æ—¥æœŸè³‡è¨Š"

def log_search_results(search_keywords: List[str], results: List[Dict]):
    """è¨˜éŒ„æœå°‹çµæœçš„è©³ç´°è³‡è¨Š"""
    print(f"\nğŸ” æœå°‹é—œéµå­—: {search_keywords}")
    print(f"ğŸ“Š ç¸½çµæœæ•¸: {len(results)}")
    
    allowed_count = sum(1 for r in results if r.get("filtered", False))
    filtered_count = len(results) - allowed_count
    
    print(f"âœ… ç¬¦åˆç¶²ç«™é™åˆ¶: {allowed_count} å€‹")
    print(f"âŒ è¢«éæ¿¾: {filtered_count} å€‹")
    
    # è¨˜éŒ„æ¯å€‹çµæœçš„è©³ç´°è³‡è¨Š
    for i, result in enumerate(results[:10], 1):  # åªè¨˜éŒ„å‰10å€‹
        title = result.get("title", "ç„¡æ¨™é¡Œ")
        link = result.get("link", "ç„¡é€£çµ")
        site_name = result.get("site_name", "æœªçŸ¥ç¶²ç«™")
        date_info = extract_date_from_result(result)
        filtered = result.get("filtered", False)
        
        status = "âœ…" if filtered else "âŒ"
        print(f"{status} {i}. [{site_name}] {title}")
        print(f"   é€£çµ: {link}")
        print(f"   æ—¥æœŸ: {date_info}")
        print()

def group_search_keywords(keywords: List[str], group_count: int = 4) -> List[List[str]]:
    """
    å°‡æœå°‹é—œéµå­—åˆ†çµ„ï¼Œå¹³å‡åˆ†é…åˆ°å¤šå€‹æœå°‹è«‹æ±‚ä¸­
    
    Args:
        keywords: æ‰€æœ‰æœå°‹é—œéµå­—
        group_count: åˆ†çµ„æ•¸é‡ï¼Œé è¨­ç‚º4çµ„
    
    Returns:
        åˆ†çµ„å¾Œçš„é—œéµå­—åˆ—è¡¨
    """
    if not keywords:
        return []
    
    # è¨ˆç®—æ¯çµ„æ‡‰è©²åŒ…å«çš„é—œéµå­—æ•¸é‡
    keywords_per_group = max(1, len(keywords) // group_count)
    
    # åˆ†çµ„
    groups = []
    for i in range(0, len(keywords), keywords_per_group):
        group = keywords[i:i + keywords_per_group]
        if group:  # ç¢ºä¿çµ„ä¸ç‚ºç©º
            groups.append(group)
    
    # å¦‚æœçµ„æ•¸ä¸è¶³ï¼Œç”¨ç©ºçµ„å¡«å……
    while len(groups) < group_count:
        groups.append([])
    
    # é™åˆ¶çµ„æ•¸
    return groups[:group_count]

def search_news_grouped(company_name: str, stock_id: str, intent: str, keywords: List[str], serper_api_key: str = None, event_type: str = '', time_info: str = '', group_count: int = 4) -> Dict:
    """
    ä½¿ç”¨åˆ†çµ„æœå°‹çš„æ–¹å¼åŸ·è¡Œæ–°èæœå°‹
    
    Args:
        company_name: å…¬å¸åç¨±
        stock_id: è‚¡ç¥¨ä»£è™Ÿ
        intent: æœå°‹æ„åœ–
        keywords: æœå°‹é—œéµå­—åˆ—è¡¨
        serper_api_key: Serper API é‡‘é‘°
        event_type: äº‹ä»¶é¡å‹
        time_info: æ™‚é–“è³‡è¨Š
        group_count: åˆ†çµ„æ•¸é‡ï¼Œé è¨­ç‚º4çµ„
    
    Returns:
        åˆä½µå¾Œçš„æœå°‹çµæœ
    """
    try:
        # å¦‚æœæ²’æœ‰æä¾› API keyï¼Œå˜—è©¦å¾ç’°å¢ƒè®Šæ•¸è®€å–
        if not serper_api_key:
            serper_api_key = os.getenv("SERPER_API_KEY")
        
        # ç”Ÿæˆæœå°‹é—œéµå­—
        all_keywords = generate_search_keywords(company_name, stock_id, intent, keywords, event_type, time_info)
        
        # åˆ†çµ„é—œéµå­—
        keyword_groups = group_search_keywords(all_keywords, group_count)
        
        print(f"ğŸ” åˆ†çµ„æœå°‹ - ç¸½é—œéµå­—æ•¸: {len(all_keywords)}")
        print(f"ğŸ“Š åˆ†çµ„æ•¸é‡: {len(keyword_groups)}")
        for i, group in enumerate(keyword_groups, 1):
            print(f"   ç¬¬{i}çµ„ ({len(group)}å€‹): {group}")
        print()
        
        # åŸ·è¡Œåˆ†çµ„æœå°‹
        all_results = []
        all_search_keywords = []
        
        for i, keyword_group in enumerate(keyword_groups, 1):
            if not keyword_group:
                continue
                
            print(f"ğŸ” åŸ·è¡Œç¬¬{i}çµ„æœå°‹...")
            
            # åŸ·è¡Œå–®çµ„æœå°‹
            group_result = search_news_single_group(
                company_name, stock_id, intent, keyword_group, serper_api_key, event_type, time_info
            )
            
            if group_result.get("success"):
                group_results = group_result.get("results", [])
                all_results.extend(group_results)
                all_search_keywords.extend(keyword_group)
                
                print(f"âœ… ç¬¬{i}çµ„æœå°‹æˆåŠŸï¼Œç²å¾— {len(group_results)} å€‹çµæœ")
            else:
                print(f"âŒ ç¬¬{i}çµ„æœå°‹å¤±æ•—: {group_result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        
        # å»é‡çµæœ
        unique_results = remove_duplicate_results(all_results)
        
        print(f"\nğŸ“Š åˆ†çµ„æœå°‹å®Œæˆ:")
        print(f"   ç¸½æœå°‹é—œéµå­—: {len(all_search_keywords)}")
        print(f"   ç¸½çµæœæ•¸: {len(all_results)}")
        print(f"   å»é‡å¾Œçµæœæ•¸: {len(unique_results)}")
        
        return {
            "success": True,
            "results": unique_results,
            "search_keywords": all_search_keywords,
            "total_groups": len(keyword_groups),
            "message": f"åˆ†çµ„æœå°‹å®Œæˆï¼Œå…±{len(keyword_groups)}çµ„ï¼Œç²å¾—{len(unique_results)}å€‹çµæœ"
        }
        
    except Exception as e:
        print(f"[search_news_grouped ERROR] {e}")
        return {
            "success": False,
            "error": f"åˆ†çµ„æœå°‹å¤±æ•—: {str(e)}",
            "results": []
        }

def search_news_single_group(company_name: str, stock_id: str, intent: str, keywords: List[str], serper_api_key: str = None, event_type: str = '', time_info: str = '') -> Dict:
    """
    åŸ·è¡Œå–®çµ„é—œéµå­—çš„æœå°‹
    """
    try:
        # å¦‚æœæ²’æœ‰æä¾› API keyï¼Œå˜—è©¦å¾ç’°å¢ƒè®Šæ•¸è®€å–
        if not serper_api_key:
            serper_api_key = os.getenv("SERPER_API_KEY")
        
        if not serper_api_key:
            return {
                "success": False,
                "error": "ç¼ºå°‘ SERPER_API_KEY",
                "results": []
            }
        
        # ä½¿ç”¨ç¬¬ä¸€å€‹é—œéµå­—é€²è¡Œæœå°‹
        if keywords:
            search_query = keywords[0]
            
            # ç™¼é€æœå°‹è«‹æ±‚
            url = "https://google.serper.dev/search"
            headers = {
                "X-API-KEY": serper_api_key,
                "Content-Type": "application/json"
            }
            
            payload = {
                "q": search_query,
                "num": 10  # æ¯çµ„æœå°‹10å€‹çµæœ
            }
            
            response = requests.post(url, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                organic_results = data.get("organic", [])
                
                # éæ¿¾çµæœ
                filtered_results = filter_results_by_site(organic_results)
                
                # è¨˜éŒ„æœå°‹çµæœ
                log_search_results(keywords, filtered_results)
                
                return {
                    "success": True,
                    "results": filtered_results,
                    "search_keywords": keywords,
                    "message": f"å–®çµ„æœå°‹æˆåŠŸï¼Œé—œéµå­—: {search_query}"
                }
            else:
                return {
                    "success": False,
                    "error": f"API è«‹æ±‚å¤±æ•—: {response.status_code}",
                    "results": []
                }
        else:
            return {
                "success": False,
                "error": "æ²’æœ‰æœå°‹é—œéµå­—",
                "results": []
            }
            
    except Exception as e:
        print(f"[search_news_single_group ERROR] {e}")
        return {
            "success": False,
            "error": f"å–®çµ„æœå°‹å¤±æ•—: {str(e)}",
            "results": []
        }

def remove_duplicate_results(results: List[Dict]) -> List[Dict]:
    """
    å»é™¤é‡è¤‡çš„æœå°‹çµæœ
    """
    seen_urls = set()
    unique_results = []
    
    for result in results:
        url = result.get("link", "")
        if url and url not in seen_urls:
            seen_urls.add(url)
            unique_results.append(result)
    
    return unique_results

def search_news(company_name: str, stock_id: str, intent: str, keywords: List[str], serper_api_key: str = None, event_type: str = '', time_info: str = '') -> Dict:
    """
    ä½¿ç”¨ Serper API æœå°‹æ–°èï¼Œä¸¦éæ¿¾ä¾†æºç¶²ç«™ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼‰
    """
    try:
        # ç”Ÿæˆæœå°‹é—œéµè©
        search_keywords = generate_search_keywords(company_name, stock_id, intent, keywords, event_type, time_info)
        
        print(f"ğŸ” ç”Ÿæˆçš„æœå°‹é—œéµå­—: {search_keywords}")
        
        # å¦‚æœæ²’æœ‰æä¾› Serper API keyï¼Œè¿”å›æ¨¡æ“¬çµæœ
        if not serper_api_key:
            mock_results = [
                {
                    "title": f"{company_name} è‚¡åƒ¹åˆ†æ - Yahooå¥‡æ‘©è‚¡å¸‚",
                    "snippet": f"æ ¹æ“šæœ€æ–°å¸‚å ´è³‡æ–™ï¼Œ{company_name}({stock_id})è¿‘æœŸè¡¨ç¾...",
                    "link": f"https://tw.finance.yahoo.com/news/{stock_id}",
                    "site_name": "tw.finance.yahoo.com",
                    "filtered": True
                },
                {
                    "title": f"{company_name} è²¡å ±åˆ†æ - é‰…äº¨ç¶²",
                    "snippet": f"{company_name}æœ€æ–°è²¡å ±é¡¯ç¤º...",
                    "link": f"https://cnyes.com/news/{stock_id}",
                    "site_name": "cnyes.com",
                    "filtered": True
                }
            ]
            
            log_search_results(search_keywords, mock_results)
            
            return {
                "success": True,
                "search_keywords": search_keywords,
                "results": mock_results,
                "message": "ä½¿ç”¨æ¨¡æ“¬è³‡æ–™ï¼ˆè«‹è¨­å®š Serper API key ä»¥ç²å–çœŸå¯¦æœå°‹çµæœï¼‰"
            }
        
        # ä½¿ç”¨ Serper API é€²è¡Œæœå°‹
        all_results = []
        
        for keyword in search_keywords:
            url = "https://google.serper.dev/search"
            headers = {
                "X-API-KEY": serper_api_key,
                "Content-Type": "application/json"
            }
            
            payload = {
                "q": keyword,
                "num": 10  # æ¯å€‹é—œéµè©æœå°‹10å€‹çµæœ
            }
            
            response = requests.post(url, headers=headers, json=payload, timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                if "organic" in data:
                    all_results.extend(data["organic"])
            else:
                print(f"Serper API è«‹æ±‚å¤±æ•—: {response.status_code}")
        
        # éæ¿¾çµæœ
        filtered_results = filter_results_by_site(all_results)
        
        # è¨˜éŒ„æœå°‹çµæœ
        log_search_results(search_keywords, filtered_results)
        
        return {
            "success": True,
            "search_keywords": search_keywords,
            "results": filtered_results[:15],  # é™åˆ¶æœ€å¤š15å€‹çµæœ
            "message": f"æˆåŠŸæœå°‹åˆ° {len(filtered_results)} å€‹ç¬¦åˆæ¢ä»¶çš„çµæœ"
        }
        
    except Exception as e:
        print(f"[search_news ERROR] {e}")
        return {
            "success": False,
            "error": str(e),
            "search_keywords": [],
            "results": []
        }

def search_news_smart(company_name: str, stock_id: str, intent: str, keywords: List[str], serper_api_key: str = None, event_type: str = '', time_info: str = '', use_grouped: bool = True) -> Dict:
    """
    æ™ºèƒ½é¸æ“‡æœå°‹æ–¹å¼
    
    Args:
        company_name: å…¬å¸åç¨±
        stock_id: è‚¡ç¥¨ä»£è™Ÿ
        intent: æœå°‹æ„åœ–
        keywords: æœå°‹é—œéµå­—åˆ—è¡¨
        serper_api_key: Serper API é‡‘é‘°
        event_type: äº‹ä»¶é¡å‹
        time_info: æ™‚é–“è³‡è¨Š
        use_grouped: æ˜¯å¦ä½¿ç”¨åˆ†çµ„æœå°‹ï¼Œé è¨­ç‚ºTrue
    
    Returns:
        æœå°‹çµæœ
    """
    if use_grouped:
        print("ğŸ” ä½¿ç”¨åˆ†çµ„æœå°‹æ¨¡å¼")
        return search_news_grouped(company_name, stock_id, intent, keywords, serper_api_key, event_type, time_info)
    else:
        print("ğŸ” ä½¿ç”¨å‚³çµ±æœå°‹æ¨¡å¼")
        return search_news(company_name, stock_id, intent, keywords, serper_api_key, event_type, time_info)

# æ¸¬è©¦ç”¨
if __name__ == "__main__":
    result = search_news(
        company_name="å°ç©é›»",
        stock_id="2330", 
        intent="å€‹è‚¡åˆ†æ",
        keywords=["è²¡å ±", "EPS"]
    )
    print(json.dumps(result, ensure_ascii=False, indent=2)) 